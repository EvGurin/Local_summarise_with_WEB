# Проект автоконспектирования видео-встреч

Данный проект позволяет:
1. Загрузить видеофайл.
2. Преобразовать его в аудио.
3. Транскрибировать аудио в текст с помощью [OpenAI Whisper](https://github.com/openai/whisper).
4. Сформировать автоматический конспект (короткую выжимку ключевых моментов) с использованием дообученной модели Llama.
5. Сформировать конспект (DOCX и TXT), а также сохранить текст транскрибации (TXT).
6. Позволять скачивать полученные файлы прямо через веб-интерфейс.

## Используемые технологии

- **Flask** в качестве веб-фреймворка (c сессиями, маршрутизацией и т. д.).
- **MoviePy** для конвертации видео в аудио.
- **OpenAI Whisper** для распознавания речи (модель загружается через `openai-whisper`).
- **Transformers** и **Torch** для работы с языковой моделью Llama (дообученной).
- **Python-Docx** для генерации DOCX-файлов.
- **Bootstrap** для базовой стилизации веб-интерфейса.
- **Нативные** средства Python для работы с очередями (модуль `queue`), потоками (модуль `threading`), обработкой исключений и т. д.

## Структура проекта

```
├── .venv                  # (виртуальное окружение, по желанию)
├── flask_session          # папка сессионных файлов Flask
├── model_32_16            # папка с дообученной моделью Llama
│   ├── config.json
│   ├── generation_config.json
│   ├── gitattributes
│   ├── pytorch_model.bin
│   ├── README.md
│   ├── special_tokens_map.json
│   ├── tokenizer.json
│   └── tokenizer_config.json
├── results                # итоговые файлы (конспекты и транскрипции)
├── static
│   └── style.css
├── templates
│   └── index.html
├── uploads                # загруженные файлы (видео)
├── requirements.txt
└── run.py                 # основной файл запуска Flask-сервера
```

### Важная информация о модели

Для полноценной работы проекта **обязательно** должна присутствовать папка `model_32_16`, в которой хранится **дообученная модель Llama**.  
Исходная модель расположена [по ссылке](https://huggingface.co/ErenBukov/llama_31_8b_7k_Dataset).  
В вашем случае требуется скачать и поместить эту модель в папку `model_32_16`, иначе проект не сможет генерировать конспекты.

## Установка и запуск

1. **Клонируйте** или скачайте данный репозиторий с исходным кодом.

2. **Создайте и активируйте виртуальное окружение** (рекомендуется, но не обязательно). Пример для Windows:
   ```bash
   python -m venv .venv
   .venv\Scripts\activate
   ```
   Или для Linux/Mac:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Установите зависимости**:
   ```bash
   pip install -r requirements.txt
   ```
   При необходимости обновите `pip`:
   ```bash
   pip install --upgrade pip
   ```

4. **Убедитесь**, что в папке `model_32_16` присутствуют файлы дообученной модели Llama, скачанные с [Hugging Face](https://huggingface.co/ErenBukov/llama_31_8b_7k_Dataset) (или другая совместимая модель).

5. **Запустите сервер** командой:
   ```bash
   python run.py
   ```
   По умолчанию сервер стартует на `http://0.0.0.0:5000`. Если сервер расположен локально, вы можете открывать в браузере `http://localhost:5000` или `http://127.0.0.1:5000`.

## Как пользоваться

1. Перейдите на страницу главного интерфейса (по умолчанию `http://localhost:5000`).
2. В форме **"Загрузить и обработать"** выберите видеофайл, который вы хотите законспектировать.
3. Нажмите на кнопку загрузки. После этого задача появится в списке ниже с уникальным ID, статусом и позицией в очереди.
4. Дождитесь, пока статус сменится на **"Завершено!"**.
5. Как только обработка завершена, становятся доступны ссылки для скачивания:
   - **Скачать .docx** — скачивает готовый конспект в формате DOCX.
   - **Скачать .txt** — скачивает готовый конспект в формате TXT.
   - **Скачать транскрипцию** — скачивает полный текст транскрибированного видео (TXT).

### Файлы

- Входные файлы (видео) сохраняются временно в папку `uploads`.
- Итоговые файлы конспектов и транскрипций сохраняются в папку `results`.
- Файлы сессий находятся в папке `flask_session`.
- Проект периодически очищает устаревшие файлы (старше 24 часов), чтобы не засорять сервер.

## Дополнительные детали

- При загрузке нескольких файлов с одинаковым именем используется префикс `uuid`, чтобы избежать перезаписи.
- Используется очередь задач: каждая задача обрабатывается последовательно в отдельном рабочем потоке.
- При желании можно изменить порт и прочие параметры, редактируя последнюю строку в `run.py`:
  ```python
  if __name__ == '__main__':
      app.run(host='0.0.0.0', port=5000, debug=False)
  ```